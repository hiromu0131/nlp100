{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロードしたデータを訓練データ用のStringと正解ラベルに分ける\n",
    "def split_vector(data):\n",
    "    dic = {'b':0, 't':1, 'e':2, 'm':3}\n",
    "    y = np.zeros(len(data) - 1)\n",
    "    x = []\n",
    "    for i, d in enumerate(data):\n",
    "        if i == len(data) - 1:\n",
    "            break\n",
    "        y[i] = dic[d[0]]\n",
    "        x.append(d[1])\n",
    "    \n",
    "    return (x, y.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8708 (8708,)\n",
      "1089 (1089,)\n",
      "1088 (1088,)\n"
     ]
    }
   ],
   "source": [
    "# 70\n",
    "file_path = 'data/NewsAggregatorDataset/'\n",
    "\n",
    "with open(file_path + 'train.txt') as f:\n",
    "    train_data = f.read().split('\\n')\n",
    "x_train, y_train = split_vector([d.split('\\t') for d in train_data])\n",
    "print(len(x_train), y_train.shape)\n",
    "\n",
    "with open(file_path + 'test.txt') as f:\n",
    "    test_data = f.read().split('\\n')\n",
    "x_test, y_test = split_vector([d.split('\\t') for d in test_data])\n",
    "print(len(x_test), y_test.shape)\n",
    "\n",
    "with open(file_path + 'valid.txt') as f:\n",
    "    valid_data = f.read().split('\\n')\n",
    "x_valid, y_valid = split_vector([d.split('\\t') for d in valid_data])\n",
    "print(len(x_valid), y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "news_path = 'data/GoogleNews-vectors-negative300.bin'\n",
    "words = KeyedVectors.load_word2vec_format(news_path, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2sum(x_data, dim):\n",
    "    pattern = re.compile(r'[a-z|A-Z]+', re.MULTILINE + re.VERBOSE)  \n",
    "    vector_sum = np.zeros((len(x_data), dim))\n",
    "    for i, s in enumerate(x_data):\n",
    "        vector = np.zeros(dim) \n",
    "        cnt = 0\n",
    "        ss = pattern.findall(s)\n",
    "        for noun in ss:\n",
    "            try :\n",
    "                cnt += 1\n",
    "                vector += words[noun]\n",
    "            except KeyError as error:\n",
    "                continue\n",
    "        if cnt == 0:\n",
    "            continue\n",
    "        vector_sum[i] = (vector / cnt)\n",
    "\n",
    "    return vector_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8708\n",
      "(8708, 300)\n"
     ]
    }
   ],
   "source": [
    "x_feature = vec2sum(x_train, 300)\n",
    "print(len(x_train))\n",
    "print(x_feature.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "dim = words['US'].shape[0] # 単語ベクトルの次元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1806, 0.1642, 0.3553, 0.2999]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# 71\n",
    "w = torch.randn(dim, 4, requires_grad = True)\n",
    "x_feature = torch.tensor(x_feature, requires_grad = True)\n",
    "y = func.softmax(torch.matmul(x_feature[:1].float(), w))\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1806, 0.1642, 0.3553, 0.2999],\n",
      "        [0.0595, 0.5623, 0.2782, 0.1000],\n",
      "        [0.1504, 0.2301, 0.5477, 0.0718],\n",
      "        [0.2057, 0.4193, 0.1192, 0.2558]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 複数事例\n",
    "Y = func.softmax(torch.mm(x_feature[:4].float(), w), dim = 1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0347, grad_fn=<NllLossBackward>)\n",
      "tensor([[-0.0030, -0.0028,  0.0108, -0.0050],\n",
      "        [ 0.0201,  0.0183, -0.0718,  0.0334],\n",
      "        [-0.0023, -0.0021,  0.0083, -0.0039],\n",
      "        ...,\n",
      "        [-0.0155, -0.0141,  0.0555, -0.0258],\n",
      "        [-0.0058, -0.0053,  0.0208, -0.0097],\n",
      "        [-0.0027, -0.0024,  0.0095, -0.0044]])\n",
      "tensor(1.4555, grad_fn=<NllLossBackward>)\n",
      "tensor([[-0.0239,  0.0244,  0.0094, -0.0099],\n",
      "        [-0.0029,  0.0440, -0.0921,  0.0511],\n",
      "        [ 0.0104, -0.0117,  0.0077, -0.0063],\n",
      "        ...,\n",
      "        [-0.0250,  0.0001,  0.0706, -0.0457],\n",
      "        [-0.0054, -0.0003,  0.0232, -0.0175],\n",
      "        [ 0.0152, -0.0095,  0.0158, -0.0214]])\n",
      "1.4555362877818967\n"
     ]
    }
   ],
   "source": [
    "from math import exp, log\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "y_train = torch.tensor(y_train.astype(float), requires_grad = True)\n",
    "\n",
    "# 単体事例\n",
    "y_ = criterion(torch.mm(x_feature[:1].float(), w), y_train[:1].long())\n",
    "print(y_)\n",
    "y_.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# 複数事例\n",
    "Y_ = criterion(torch.mm(x_feature[:4].float(), w), y_train[:4].long())\n",
    "print(Y_)\n",
    "Y_.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# 検算\n",
    "ans = []\n",
    "for yy, i in zip(Y, y_train[:4].long()):\n",
    "    ans.append(-log(yy[i]))\n",
    "print(sum(ans) / len(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = MyNet(dim)\n",
    "optimizer = optim.SGD(mynet.parameters(), lr = 0.01, momentum = 0.9)\n",
    "num_epochs = 100\n",
    "save_path = '../data/params.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def set_params(self, num_epochs, num_batches, optimizer, criterion, x_valid, y_valid):\n",
    "        # エポック数，バッチサイズ，最適化アルゴリズム，損失関数の初期化\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_batches = num_batches\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.x_valid = torch.tensor(x_valid).float()\n",
    "        self.y_valid = torch.tensor(y_valid).long()\n",
    "        \n",
    "        # epoch毎の損失と精度を保持するリスト\n",
    "        self.train_score = np.zeros(num_epochs)        \n",
    "        self.train_loss = np.zeros(num_epochs)\n",
    "        self.valid_score = np.zeros(num_epochs)\n",
    "        self.valid_loss = np.zeros(num_epochs)\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        num_data = x_train.shape[0]\n",
    "        for epoch in range(self.num_epochs):\n",
    "\n",
    "            # epoch毎の損失と精度\n",
    "            running_loss = 0.0\n",
    "            accuracy = 0.0\n",
    "\n",
    "            # 開始時間\n",
    "            t = time.time()\n",
    "\n",
    "            # ミニバッチ学習のために訓練データのインデックスをランダムに並べ替える\n",
    "            index = np.random.permutation(num_data)\n",
    "\n",
    "            for i in range(0, num_data, self.num_batches):\n",
    "                # NNへの入力と正解ラベル\n",
    "                in_, label = torch.tensor(x_train[index[i : i + self.num_batches if i + self.num_batches < num_data else num_data]]), \\\n",
    "                             torch.tensor(y_train[index[i : i + self.num_batches if i + self.num_batches < num_data else num_data]]).long()\n",
    "\n",
    "                # 最適化関数の初期化\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # 予測とロスの計算\n",
    "                out_ = self.model(in_.float())\n",
    "                loss = self.criterion(out_, label)\n",
    "                _, idx = torch.max(out_, 1)\n",
    "\n",
    "                # バッチ数のラベルより正解数のカウント\n",
    "                accuracy += (np.sum(idx.numpy() == label.numpy()) / idx.shape[0])\n",
    "\n",
    "                # パラメーターの更新\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.data\n",
    "                \n",
    "            out_ = self.model(self.x_valid)\n",
    "            _, idx = torch.max(out_, 1)\n",
    "            v_accuracy = self.evaluate(self.x_valid, self.y_valid)\n",
    "            v_loss = self.criterion(out_, self.y_valid)\n",
    "            v_loss.backward()\n",
    "\n",
    "            # 各種データの出力・保存\n",
    "            num_loop = num_data / self.num_batches\n",
    "            accuracy /= num_loop\n",
    "            loss = running_loss / num_loop\n",
    "            print('[ epoch:{0}, time:{3} ]  acc: {1:.4f}  loss:{2:.4f}'.format(epoch + 1, accuracy, loss, time.time() - t))\n",
    "            self.train_score[epoch] = accuracy\n",
    "            self.train_loss[epoch] = loss\n",
    "            self.valid_score[epoch] = v_accuracy\n",
    "            self.valid_loss[epoch] = v_loss.data\n",
    "\n",
    " \n",
    "            # 状況の保存\n",
    "            torch.save({\n",
    "              'epoch': epoch,\n",
    "              'model_state_dict': self.model.state_dict(),\n",
    "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "              'loss': loss,\n",
    "              'accuracy': accuracy,\n",
    "              }, save_path)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        out_ = self.model(x)\n",
    "        return out_\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        p = self.predict(x)\n",
    "        _, idx = torch.max(p, 1)\n",
    "        accuracy = np.sum(idx.numpy() == y.numpy()) / idx.shape[0]\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def visualize(self):\n",
    "        x = np.arange(len(self.train_score))\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(211)\n",
    "        ax.plot(x, self.train_score, color = 'red', linewidth = 2, label = 'train_score')\n",
    "        ax.plot(x, self.valid_score, color = 'blue', linewidth = 1, label = 'valid_score', linestyle = 'dashed')\n",
    "\n",
    "        ax2 = fig.add_subplot(212)\n",
    "        ax2.plot(x, self.train_loss, color = 'green', linewidth = 2, label = 'train_loss')\n",
    "        ax2.plot(x, self.valid_loss, color = 'blue', linewidth = 1, label = 'valid_loss', linestyle = 'dashed')\n",
    "        ax.legend()\n",
    "        ax2.legend()\n",
    "        plt.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(mynet)\n",
    "model.set_params(num_epochs, 16, optimizer, criterion, vec2sum(x_valid, dim), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:0.19979095458984375 ]  acc: 0.7901  loss:0.7395\n",
      "[ epoch:2, time:0.22914886474609375 ]  acc: 0.8273  loss:0.5138\n",
      "[ epoch:3, time:0.21206021308898926 ]  acc: 0.8485  loss:0.4409\n",
      "[ epoch:4, time:0.21294784545898438 ]  acc: 0.8674  loss:0.3986\n",
      "[ epoch:5, time:0.2129840850830078 ]  acc: 0.8799  loss:0.3698\n",
      "[ epoch:6, time:0.21240520477294922 ]  acc: 0.8892  loss:0.3494\n",
      "[ epoch:7, time:0.21036005020141602 ]  acc: 0.8937  loss:0.3340\n",
      "[ epoch:8, time:0.21610808372497559 ]  acc: 0.8976  loss:0.3220\n",
      "[ epoch:9, time:0.21641111373901367 ]  acc: 0.9010  loss:0.3129\n",
      "[ epoch:10, time:0.2149200439453125 ]  acc: 0.9025  loss:0.3038\n",
      "[ epoch:11, time:0.22524690628051758 ]  acc: 0.9050  loss:0.2970\n",
      "[ epoch:12, time:0.22061514854431152 ]  acc: 0.9078  loss:0.2913\n",
      "[ epoch:13, time:0.21181893348693848 ]  acc: 0.9078  loss:0.2864\n",
      "[ epoch:14, time:0.21261191368103027 ]  acc: 0.9099  loss:0.2825\n",
      "[ epoch:15, time:0.21867704391479492 ]  acc: 0.9112  loss:0.2770\n",
      "[ epoch:16, time:0.23090600967407227 ]  acc: 0.9120  loss:0.2736\n",
      "[ epoch:17, time:0.23098206520080566 ]  acc: 0.9127  loss:0.2700\n",
      "[ epoch:18, time:0.22693920135498047 ]  acc: 0.9135  loss:0.2667\n",
      "[ epoch:19, time:0.2303478717803955 ]  acc: 0.9139  loss:0.2643\n",
      "[ epoch:20, time:0.22949671745300293 ]  acc: 0.9154  loss:0.2615\n",
      "[ epoch:21, time:0.22862696647644043 ]  acc: 0.9144  loss:0.2595\n",
      "[ epoch:22, time:0.2278461456298828 ]  acc: 0.9173  loss:0.2569\n",
      "[ epoch:23, time:0.2212841510772705 ]  acc: 0.9172  loss:0.2549\n",
      "[ epoch:24, time:0.2137138843536377 ]  acc: 0.9179  loss:0.2521\n",
      "[ epoch:25, time:0.22056984901428223 ]  acc: 0.9188  loss:0.2510\n",
      "[ epoch:26, time:0.21738505363464355 ]  acc: 0.9188  loss:0.2499\n",
      "[ epoch:27, time:0.22519183158874512 ]  acc: 0.9189  loss:0.2479\n",
      "[ epoch:28, time:0.22778701782226562 ]  acc: 0.9194  loss:0.2465\n",
      "[ epoch:29, time:0.23151898384094238 ]  acc: 0.9208  loss:0.2444\n",
      "[ epoch:30, time:0.2270069122314453 ]  acc: 0.9206  loss:0.2432\n",
      "[ epoch:31, time:0.22650408744812012 ]  acc: 0.9213  loss:0.2422\n",
      "[ epoch:32, time:0.22930002212524414 ]  acc: 0.9220  loss:0.2402\n",
      "[ epoch:33, time:0.22998309135437012 ]  acc: 0.9211  loss:0.2399\n",
      "[ epoch:34, time:0.21998286247253418 ]  acc: 0.9227  loss:0.2381\n",
      "[ epoch:35, time:0.21087217330932617 ]  acc: 0.9234  loss:0.2367\n",
      "[ epoch:36, time:0.226790189743042 ]  acc: 0.9227  loss:0.2363\n",
      "[ epoch:37, time:0.22717690467834473 ]  acc: 0.9223  loss:0.2344\n",
      "[ epoch:38, time:0.22811508178710938 ]  acc: 0.9241  loss:0.2335\n",
      "[ epoch:39, time:0.22511672973632812 ]  acc: 0.9256  loss:0.2338\n",
      "[ epoch:40, time:0.2121882438659668 ]  acc: 0.9248  loss:0.2318\n",
      "[ epoch:41, time:0.22078227996826172 ]  acc: 0.9255  loss:0.2309\n",
      "[ epoch:42, time:0.21674895286560059 ]  acc: 0.9231  loss:0.2297\n",
      "[ epoch:43, time:0.22201800346374512 ]  acc: 0.9251  loss:0.2296\n",
      "[ epoch:44, time:0.22908401489257812 ]  acc: 0.9255  loss:0.2282\n",
      "[ epoch:45, time:0.23035001754760742 ]  acc: 0.9258  loss:0.2280\n",
      "[ epoch:46, time:0.22986698150634766 ]  acc: 0.9259  loss:0.2268\n",
      "[ epoch:47, time:0.21117377281188965 ]  acc: 0.9255  loss:0.2262\n",
      "[ epoch:48, time:0.2099010944366455 ]  acc: 0.9262  loss:0.2252\n",
      "[ epoch:49, time:0.21647310256958008 ]  acc: 0.9266  loss:0.2245\n",
      "[ epoch:50, time:0.21509575843811035 ]  acc: 0.9257  loss:0.2242\n",
      "[ epoch:51, time:0.21228981018066406 ]  acc: 0.9275  loss:0.2230\n",
      "[ epoch:52, time:0.21513104438781738 ]  acc: 0.9270  loss:0.2224\n",
      "[ epoch:53, time:0.20953798294067383 ]  acc: 0.9272  loss:0.2217\n",
      "[ epoch:54, time:0.21079492568969727 ]  acc: 0.9274  loss:0.2212\n",
      "[ epoch:55, time:0.20938897132873535 ]  acc: 0.9275  loss:0.2205\n",
      "[ epoch:56, time:0.20903897285461426 ]  acc: 0.9273  loss:0.2209\n",
      "[ epoch:57, time:0.2085587978363037 ]  acc: 0.9271  loss:0.2204\n",
      "[ epoch:58, time:0.2077789306640625 ]  acc: 0.9288  loss:0.2189\n",
      "[ epoch:59, time:0.21456503868103027 ]  acc: 0.9273  loss:0.2187\n",
      "[ epoch:60, time:0.2167208194732666 ]  acc: 0.9273  loss:0.2176\n",
      "[ epoch:61, time:0.2167057991027832 ]  acc: 0.9283  loss:0.2170\n",
      "[ epoch:62, time:0.21344470977783203 ]  acc: 0.9273  loss:0.2164\n",
      "[ epoch:63, time:0.21410584449768066 ]  acc: 0.9279  loss:0.2162\n",
      "[ epoch:64, time:0.22167420387268066 ]  acc: 0.9278  loss:0.2156\n",
      "[ epoch:65, time:0.2146167755126953 ]  acc: 0.9286  loss:0.2151\n",
      "[ epoch:66, time:0.21296215057373047 ]  acc: 0.9290  loss:0.2145\n",
      "[ epoch:67, time:0.2125990390777588 ]  acc: 0.9282  loss:0.2141\n",
      "[ epoch:68, time:0.2154250144958496 ]  acc: 0.9287  loss:0.2140\n",
      "[ epoch:69, time:0.21337294578552246 ]  acc: 0.9286  loss:0.2131\n",
      "[ epoch:70, time:0.21472406387329102 ]  acc: 0.9296  loss:0.2127\n",
      "[ epoch:71, time:0.21438002586364746 ]  acc: 0.9287  loss:0.2127\n",
      "[ epoch:72, time:0.21565604209899902 ]  acc: 0.9302  loss:0.2116\n",
      "[ epoch:73, time:0.2125248908996582 ]  acc: 0.9296  loss:0.2112\n",
      "[ epoch:74, time:0.21358203887939453 ]  acc: 0.9291  loss:0.2107\n",
      "[ epoch:75, time:0.20908498764038086 ]  acc: 0.9278  loss:0.2114\n",
      "[ epoch:76, time:0.20762300491333008 ]  acc: 0.9296  loss:0.2100\n",
      "[ epoch:77, time:0.20966506004333496 ]  acc: 0.9287  loss:0.2125\n",
      "[ epoch:78, time:0.2088029384613037 ]  acc: 0.9299  loss:0.2093\n",
      "[ epoch:79, time:0.20939970016479492 ]  acc: 0.9298  loss:0.2088\n",
      "[ epoch:80, time:0.21071290969848633 ]  acc: 0.9297  loss:0.2084\n",
      "[ epoch:81, time:0.21330690383911133 ]  acc: 0.9299  loss:0.2083\n",
      "[ epoch:82, time:0.21326613426208496 ]  acc: 0.9310  loss:0.2080\n",
      "[ epoch:83, time:0.21330618858337402 ]  acc: 0.9296  loss:0.2079\n",
      "[ epoch:84, time:0.21547794342041016 ]  acc: 0.9297  loss:0.2069\n",
      "[ epoch:85, time:0.2142338752746582 ]  acc: 0.9306  loss:0.2065\n",
      "[ epoch:86, time:0.21735715866088867 ]  acc: 0.9302  loss:0.2067\n",
      "[ epoch:87, time:0.2138080596923828 ]  acc: 0.9299  loss:0.2065\n",
      "[ epoch:88, time:0.21442103385925293 ]  acc: 0.9306  loss:0.2059\n",
      "[ epoch:89, time:0.2142467498779297 ]  acc: 0.9303  loss:0.2055\n",
      "[ epoch:90, time:0.21341681480407715 ]  acc: 0.9304  loss:0.2063\n",
      "[ epoch:91, time:0.2138221263885498 ]  acc: 0.9305  loss:0.2046\n",
      "[ epoch:92, time:0.21308326721191406 ]  acc: 0.9302  loss:0.2047\n",
      "[ epoch:93, time:0.2235260009765625 ]  acc: 0.9309  loss:0.2041\n",
      "[ epoch:94, time:0.21503305435180664 ]  acc: 0.9309  loss:0.2038\n",
      "[ epoch:95, time:0.21357202529907227 ]  acc: 0.9311  loss:0.2034\n",
      "[ epoch:96, time:0.2131209373474121 ]  acc: 0.9297  loss:0.2036\n",
      "[ epoch:97, time:0.2140190601348877 ]  acc: 0.9313  loss:0.2028\n",
      "[ epoch:98, time:0.21331310272216797 ]  acc: 0.9305  loss:0.2028\n",
      "[ epoch:99, time:0.21289396286010742 ]  acc: 0.9313  loss:0.2022\n",
      "[ epoch:100, time:0.2129359245300293 ]  acc: 0.9317  loss:0.2021\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9299494717501149"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_feature.float(), torch.tensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9246323529411765"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(torch.tensor(vec2sum(x_valid, dim), requires_grad = True).float(), torch.tensor(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439853076216712"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(torch.tensor(vec2sum(x_test, dim), requires_grad = True).float(), torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(mynet)\n",
    "model2.set_params(num_epochs, 4, optimizer, criterion, vec2sum(x_valid, dim), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:0.6712989807128906 ]  acc: 0.9296  loss:0.2029\n",
      "[ epoch:2, time:0.7032830715179443 ]  acc: 0.9297  loss:0.2019\n",
      "[ epoch:3, time:0.7054562568664551 ]  acc: 0.9299  loss:0.2007\n",
      "[ epoch:4, time:0.707669734954834 ]  acc: 0.9298  loss:0.1998\n",
      "[ epoch:5, time:0.6924247741699219 ]  acc: 0.9303  loss:0.1990\n",
      "[ epoch:6, time:0.7187838554382324 ]  acc: 0.9305  loss:0.1981\n",
      "[ epoch:7, time:0.7493162155151367 ]  acc: 0.9318  loss:0.1970\n",
      "[ epoch:8, time:0.7304482460021973 ]  acc: 0.9308  loss:0.1966\n",
      "[ epoch:9, time:0.7042572498321533 ]  acc: 0.9321  loss:0.1956\n",
      "[ epoch:10, time:0.7345411777496338 ]  acc: 0.9318  loss:0.1948\n",
      "[ epoch:11, time:0.7207117080688477 ]  acc: 0.9327  loss:0.1941\n",
      "[ epoch:12, time:0.7573330402374268 ]  acc: 0.9324  loss:0.1932\n",
      "[ epoch:13, time:0.6969561576843262 ]  acc: 0.9333  loss:0.1928\n",
      "[ epoch:14, time:0.6941943168640137 ]  acc: 0.9332  loss:0.1919\n",
      "[ epoch:15, time:0.6937708854675293 ]  acc: 0.9337  loss:0.1915\n",
      "[ epoch:16, time:0.6994380950927734 ]  acc: 0.9345  loss:0.1908\n",
      "[ epoch:17, time:0.6990196704864502 ]  acc: 0.9332  loss:0.1902\n",
      "[ epoch:18, time:0.6950101852416992 ]  acc: 0.9342  loss:0.1899\n",
      "[ epoch:19, time:0.6960947513580322 ]  acc: 0.9340  loss:0.1891\n",
      "[ epoch:20, time:0.6997110843658447 ]  acc: 0.9333  loss:0.1883\n",
      "[ epoch:21, time:0.6963009834289551 ]  acc: 0.9342  loss:0.1878\n",
      "[ epoch:22, time:0.7156269550323486 ]  acc: 0.9350  loss:0.1869\n",
      "[ epoch:23, time:0.7471327781677246 ]  acc: 0.9341  loss:0.1873\n",
      "[ epoch:24, time:0.7482559680938721 ]  acc: 0.9334  loss:0.1865\n",
      "[ epoch:25, time:0.7162511348724365 ]  acc: 0.9341  loss:0.1863\n",
      "[ epoch:26, time:0.7244560718536377 ]  acc: 0.9342  loss:0.1858\n",
      "[ epoch:27, time:0.7268106937408447 ]  acc: 0.9357  loss:0.1852\n",
      "[ epoch:28, time:0.7153301239013672 ]  acc: 0.9334  loss:0.1851\n",
      "[ epoch:29, time:0.7156543731689453 ]  acc: 0.9348  loss:0.1844\n",
      "[ epoch:30, time:0.7227411270141602 ]  acc: 0.9355  loss:0.1843\n",
      "[ epoch:31, time:0.7708330154418945 ]  acc: 0.9348  loss:0.1839\n",
      "[ epoch:32, time:0.7490136623382568 ]  acc: 0.9359  loss:0.1833\n",
      "[ epoch:33, time:0.749424934387207 ]  acc: 0.9362  loss:0.1825\n",
      "[ epoch:34, time:0.7431318759918213 ]  acc: 0.9358  loss:0.1824\n",
      "[ epoch:35, time:0.7337830066680908 ]  acc: 0.9350  loss:0.1821\n",
      "[ epoch:36, time:0.7195448875427246 ]  acc: 0.9355  loss:0.1817\n",
      "[ epoch:37, time:0.7183091640472412 ]  acc: 0.9362  loss:0.1815\n",
      "[ epoch:38, time:0.7222728729248047 ]  acc: 0.9356  loss:0.1811\n",
      "[ epoch:39, time:0.7038447856903076 ]  acc: 0.9351  loss:0.1805\n",
      "[ epoch:40, time:0.6957738399505615 ]  acc: 0.9368  loss:0.1798\n",
      "[ epoch:41, time:0.6887459754943848 ]  acc: 0.9366  loss:0.1801\n",
      "[ epoch:42, time:0.6910290718078613 ]  acc: 0.9357  loss:0.1799\n",
      "[ epoch:43, time:0.6856729984283447 ]  acc: 0.9370  loss:0.1796\n",
      "[ epoch:44, time:0.6891438961029053 ]  acc: 0.9360  loss:0.1789\n",
      "[ epoch:45, time:0.6919009685516357 ]  acc: 0.9370  loss:0.1787\n",
      "[ epoch:46, time:0.6896660327911377 ]  acc: 0.9373  loss:0.1785\n",
      "[ epoch:47, time:0.6916210651397705 ]  acc: 0.9368  loss:0.1782\n",
      "[ epoch:48, time:0.6911890506744385 ]  acc: 0.9372  loss:0.1780\n",
      "[ epoch:49, time:0.6911368370056152 ]  acc: 0.9375  loss:0.1775\n",
      "[ epoch:50, time:0.6983499526977539 ]  acc: 0.9371  loss:0.1774\n",
      "[ epoch:51, time:0.692523717880249 ]  acc: 0.9370  loss:0.1775\n",
      "[ epoch:52, time:0.6912858486175537 ]  acc: 0.9379  loss:0.1770\n",
      "[ epoch:53, time:0.7002906799316406 ]  acc: 0.9384  loss:0.1764\n",
      "[ epoch:54, time:0.6949691772460938 ]  acc: 0.9387  loss:0.1760\n",
      "[ epoch:55, time:0.6912240982055664 ]  acc: 0.9375  loss:0.1762\n",
      "[ epoch:56, time:0.6985821723937988 ]  acc: 0.9376  loss:0.1758\n",
      "[ epoch:57, time:0.6914129257202148 ]  acc: 0.9375  loss:0.1756\n",
      "[ epoch:58, time:0.6956930160522461 ]  acc: 0.9362  loss:0.1752\n",
      "[ epoch:59, time:0.6957240104675293 ]  acc: 0.9378  loss:0.1755\n",
      "[ epoch:60, time:0.691727876663208 ]  acc: 0.9389  loss:0.1749\n",
      "[ epoch:61, time:0.696617841720581 ]  acc: 0.9376  loss:0.1750\n",
      "[ epoch:62, time:0.6952409744262695 ]  acc: 0.9387  loss:0.1746\n",
      "[ epoch:63, time:0.6947529315948486 ]  acc: 0.9379  loss:0.1747\n",
      "[ epoch:64, time:0.6929459571838379 ]  acc: 0.9372  loss:0.1742\n",
      "[ epoch:65, time:0.6985158920288086 ]  acc: 0.9380  loss:0.1742\n",
      "[ epoch:66, time:0.6914780139923096 ]  acc: 0.9379  loss:0.1739\n",
      "[ epoch:67, time:0.696458101272583 ]  acc: 0.9375  loss:0.1739\n",
      "[ epoch:68, time:0.6904866695404053 ]  acc: 0.9386  loss:0.1731\n",
      "[ epoch:69, time:0.698040246963501 ]  acc: 0.9390  loss:0.1728\n",
      "[ epoch:70, time:0.6981308460235596 ]  acc: 0.9384  loss:0.1735\n",
      "[ epoch:71, time:0.6940412521362305 ]  acc: 0.9381  loss:0.1730\n",
      "[ epoch:72, time:0.706061840057373 ]  acc: 0.9382  loss:0.1728\n",
      "[ epoch:73, time:0.700261116027832 ]  acc: 0.9403  loss:0.1722\n",
      "[ epoch:74, time:0.6929621696472168 ]  acc: 0.9381  loss:0.1726\n",
      "[ epoch:75, time:0.6951920986175537 ]  acc: 0.9398  loss:0.1726\n",
      "[ epoch:76, time:0.7110960483551025 ]  acc: 0.9387  loss:0.1720\n",
      "[ epoch:77, time:0.6929028034210205 ]  acc: 0.9386  loss:0.1719\n",
      "[ epoch:78, time:0.6975412368774414 ]  acc: 0.9391  loss:0.1716\n",
      "[ epoch:79, time:0.6944470405578613 ]  acc: 0.9387  loss:0.1714\n",
      "[ epoch:80, time:0.7018921375274658 ]  acc: 0.9396  loss:0.1713\n",
      "[ epoch:81, time:0.7074477672576904 ]  acc: 0.9398  loss:0.1712\n",
      "[ epoch:82, time:0.6994051933288574 ]  acc: 0.9386  loss:0.1712\n",
      "[ epoch:83, time:0.7408530712127686 ]  acc: 0.9388  loss:0.1706\n",
      "[ epoch:84, time:0.6987590789794922 ]  acc: 0.9397  loss:0.1707\n",
      "[ epoch:85, time:0.6930532455444336 ]  acc: 0.9388  loss:0.1710\n",
      "[ epoch:86, time:0.6961920261383057 ]  acc: 0.9393  loss:0.1706\n",
      "[ epoch:87, time:0.6902048587799072 ]  acc: 0.9396  loss:0.1704\n",
      "[ epoch:88, time:0.6967389583587646 ]  acc: 0.9397  loss:0.1704\n",
      "[ epoch:89, time:0.6900789737701416 ]  acc: 0.9402  loss:0.1701\n",
      "[ epoch:90, time:0.6905667781829834 ]  acc: 0.9394  loss:0.1702\n",
      "[ epoch:91, time:0.6940591335296631 ]  acc: 0.9394  loss:0.1699\n",
      "[ epoch:92, time:0.6923799514770508 ]  acc: 0.9397  loss:0.1695\n",
      "[ epoch:93, time:0.6949949264526367 ]  acc: 0.9398  loss:0.1697\n",
      "[ epoch:94, time:0.6952550411224365 ]  acc: 0.9407  loss:0.1690\n",
      "[ epoch:95, time:0.6936841011047363 ]  acc: 0.9399  loss:0.1691\n",
      "[ epoch:96, time:0.6931469440460205 ]  acc: 0.9411  loss:0.1694\n",
      "[ epoch:97, time:0.696491003036499 ]  acc: 0.9397  loss:0.1690\n",
      "[ epoch:98, time:0.6918599605560303 ]  acc: 0.9397  loss:0.1688\n",
      "[ epoch:99, time:0.7177889347076416 ]  acc: 0.9406  loss:0.1690\n",
      "[ epoch:100, time:0.74005126953125 ]  acc: 0.9401  loss:0.1685\n"
     ]
    }
   ],
   "source": [
    "model2.fit(x_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet2(nn.Module):\n",
    "    def __init__(self, input_size, h_size, output_size):\n",
    "        super(MyNet2, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, h_size)\n",
    "        self.fc2 = torch.nn.Linear(h_size, int(h_size / 2))\n",
    "        self.fc3 = torch.nn.Linear(int(h_size / 2), output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = func.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = func.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = MyNet2(dim, 100, 4)\n",
    "optimizer = optim.SGD(mynet.parameters(), lr = 0.01, momentum = 0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "save_path = '../data/params.tar'\n",
    "\n",
    "model = Model(mynet)\n",
    "model.set_params(num_epochs, 2, optimizer, criterion, vec2sum(x_valid, dim), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:2.714562177658081 ]  acc: 0.8511  loss:0.4141\n",
      "[ epoch:2, time:2.7528021335601807 ]  acc: 0.9099  loss:0.2652\n",
      "[ epoch:3, time:2.709635019302368 ]  acc: 0.9181  loss:0.2313\n",
      "[ epoch:4, time:2.730846881866455 ]  acc: 0.9212  loss:0.2175\n",
      "[ epoch:5, time:2.64666485786438 ]  acc: 0.9267  loss:0.1999\n",
      "[ epoch:6, time:2.613356590270996 ]  acc: 0.9305  loss:0.1868\n",
      "[ epoch:7, time:2.618211269378662 ]  acc: 0.9353  loss:0.1793\n",
      "[ epoch:8, time:2.604094982147217 ]  acc: 0.9393  loss:0.1616\n",
      "[ epoch:9, time:2.6057159900665283 ]  acc: 0.9443  loss:0.1527\n",
      "[ epoch:10, time:2.610842227935791 ]  acc: 0.9445  loss:0.1453\n",
      "[ epoch:11, time:2.598304033279419 ]  acc: 0.9496  loss:0.1303\n",
      "[ epoch:12, time:2.6054847240448 ]  acc: 0.9540  loss:0.1230\n",
      "[ epoch:13, time:2.649444818496704 ]  acc: 0.9580  loss:0.1149\n",
      "[ epoch:14, time:2.7256112098693848 ]  acc: 0.9596  loss:0.1037\n",
      "[ epoch:15, time:2.8109450340270996 ]  acc: 0.9613  loss:0.1016\n",
      "[ epoch:16, time:2.7816641330718994 ]  acc: 0.9661  loss:0.0870\n",
      "[ epoch:17, time:2.7483646869659424 ]  acc: 0.9712  loss:0.0791\n",
      "[ epoch:18, time:2.7227699756622314 ]  acc: 0.9743  loss:0.0683\n",
      "[ epoch:19, time:2.724498987197876 ]  acc: 0.9728  loss:0.0703\n",
      "[ epoch:20, time:2.7031428813934326 ]  acc: 0.9783  loss:0.0613\n",
      "[ epoch:21, time:2.8505349159240723 ]  acc: 0.9796  loss:0.0564\n",
      "[ epoch:22, time:2.754547119140625 ]  acc: 0.9824  loss:0.0486\n",
      "[ epoch:23, time:2.8249518871307373 ]  acc: 0.9823  loss:0.0485\n",
      "[ epoch:24, time:2.6825311183929443 ]  acc: 0.9823  loss:0.0533\n",
      "[ epoch:25, time:2.7315728664398193 ]  acc: 0.9878  loss:0.0322\n",
      "[ epoch:26, time:2.851830005645752 ]  acc: 0.9871  loss:0.0386\n",
      "[ epoch:27, time:2.840452194213867 ]  acc: 0.9881  loss:0.0381\n",
      "[ epoch:28, time:2.9222941398620605 ]  acc: 0.9891  loss:0.0307\n",
      "[ epoch:29, time:2.824176073074341 ]  acc: 0.9898  loss:0.0332\n",
      "[ epoch:30, time:2.6905479431152344 ]  acc: 0.9835  loss:0.0471\n",
      "[ epoch:31, time:2.6446609497070312 ]  acc: 0.9887  loss:0.0326\n",
      "[ epoch:32, time:2.639431953430176 ]  acc: 0.9938  loss:0.0223\n",
      "[ epoch:33, time:2.664642095565796 ]  acc: 0.9953  loss:0.0139\n",
      "[ epoch:34, time:2.619124174118042 ]  acc: 0.9898  loss:0.0315\n",
      "[ epoch:35, time:2.6280760765075684 ]  acc: 0.9940  loss:0.0178\n",
      "[ epoch:36, time:2.6264803409576416 ]  acc: 0.9900  loss:0.0300\n",
      "[ epoch:37, time:2.6637721061706543 ]  acc: 0.9929  loss:0.0231\n",
      "[ epoch:38, time:2.650630235671997 ]  acc: 0.9962  loss:0.0122\n",
      "[ epoch:39, time:2.6132209300994873 ]  acc: 0.9971  loss:0.0078\n",
      "[ epoch:40, time:2.6310830116271973 ]  acc: 0.9964  loss:0.0112\n",
      "[ epoch:41, time:2.8603601455688477 ]  acc: 0.9941  loss:0.0160\n",
      "[ epoch:42, time:3.172529935836792 ]  acc: 0.9959  loss:0.0111\n",
      "[ epoch:43, time:3.1665091514587402 ]  acc: 0.9977  loss:0.0061\n",
      "[ epoch:44, time:3.0647950172424316 ]  acc: 0.9985  loss:0.0041\n",
      "[ epoch:45, time:3.0637388229370117 ]  acc: 0.9974  loss:0.0089\n",
      "[ epoch:46, time:3.1743686199188232 ]  acc: 0.9984  loss:0.0039\n",
      "[ epoch:47, time:3.141615867614746 ]  acc: 0.9983  loss:0.0041\n",
      "[ epoch:48, time:3.5938010215759277 ]  acc: 0.9980  loss:0.0047\n",
      "[ epoch:49, time:3.2283999919891357 ]  acc: 0.9986  loss:0.0036\n",
      "[ epoch:50, time:2.938998222351074 ]  acc: 0.9986  loss:0.0030\n",
      "[ epoch:51, time:2.744554042816162 ]  acc: 0.9980  loss:0.0033\n",
      "[ epoch:52, time:2.640065908432007 ]  acc: 0.9986  loss:0.0024\n",
      "[ epoch:53, time:2.6437430381774902 ]  acc: 0.9987  loss:0.0022\n",
      "[ epoch:54, time:2.635673761367798 ]  acc: 0.9987  loss:0.0023\n",
      "[ epoch:55, time:2.6803171634674072 ]  acc: 0.9989  loss:0.0022\n",
      "[ epoch:56, time:2.759212017059326 ]  acc: 0.9987  loss:0.0025\n",
      "[ epoch:57, time:2.8145337104797363 ]  acc: 0.9985  loss:0.0023\n",
      "[ epoch:58, time:2.782494068145752 ]  acc: 0.9989  loss:0.0025\n",
      "[ epoch:59, time:2.739129066467285 ]  acc: 0.9984  loss:0.0023\n",
      "[ epoch:60, time:2.7765157222747803 ]  acc: 0.9986  loss:0.0024\n",
      "[ epoch:61, time:2.757193088531494 ]  acc: 0.9983  loss:0.0041\n",
      "[ epoch:62, time:2.7129580974578857 ]  acc: 0.9979  loss:0.0037\n",
      "[ epoch:63, time:2.7697768211364746 ]  acc: 0.9989  loss:0.0023\n",
      "[ epoch:64, time:2.7210028171539307 ]  acc: 0.9989  loss:0.0021\n",
      "[ epoch:65, time:2.712074041366577 ]  acc: 0.9986  loss:0.0023\n",
      "[ epoch:66, time:2.70854115486145 ]  acc: 0.9986  loss:0.0023\n",
      "[ epoch:67, time:2.730151891708374 ]  acc: 0.9986  loss:0.0022\n",
      "[ epoch:68, time:2.6814322471618652 ]  acc: 0.9987  loss:0.0021\n",
      "[ epoch:69, time:2.757913112640381 ]  acc: 0.9987  loss:0.0024\n",
      "[ epoch:70, time:2.700969934463501 ]  acc: 0.9984  loss:0.0022\n",
      "[ epoch:71, time:2.687479019165039 ]  acc: 0.9985  loss:0.0021\n",
      "[ epoch:72, time:2.6531999111175537 ]  acc: 0.9987  loss:0.0021\n",
      "[ epoch:73, time:2.6660959720611572 ]  acc: 0.9985  loss:0.0021\n",
      "[ epoch:74, time:2.73445987701416 ]  acc: 0.9987  loss:0.0021\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_feature.float(), torch.tensor(y_train))\n",
    "model.evaluate(torch.tensor(vec2sum(x_valid, dim), requires_grad = True).float(), torch.tensor(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
