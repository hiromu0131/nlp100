{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロードしたデータを訓練データ用のStringと正解ラベルに分ける\n",
    "def split_vector(data):\n",
    "    y = np.zeros(len(data) - 1)\n",
    "    x = []\n",
    "    for i, d in enumerate(data):\n",
    "        if i == len(data) - 1:\n",
    "            break\n",
    "        c = 3\n",
    "        if (d[0] == 'b') : c = 0\n",
    "        if (d[0] == 't') : c = 1\n",
    "        if (d[0] == 'e') : c = 2\n",
    "        y[i] = c\n",
    "        x.append(d[1])\n",
    "    \n",
    "    return (x, y.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8708 (8708,)\n",
      "1099 (1099,)\n",
      "1088 (1088,)\n"
     ]
    }
   ],
   "source": [
    "# 70\n",
    "file_path = '../data/NewsAggregatorDataset/'\n",
    "\n",
    "with open(file_path + 'train.txt') as f:\n",
    "    train_data = f.read().split('\\n')\n",
    "x_train, y_train = split_vector([d.split('\\t') for d in train_data])\n",
    "print(len(x_train), y_train.shape)\n",
    "\n",
    "with open(file_path + 'test.txt') as f:\n",
    "    test_data = f.read().split('\\n')\n",
    "x_test, y_test = split_vector([d.split('\\t') for d in test_data])\n",
    "print(len(x_test), y_test.shape)\n",
    "\n",
    "with open(file_path + 'valid.txt') as f:\n",
    "    valid_data = f.read().split('\\n')\n",
    "x_valid, y_valid = split_vector([d.split('\\t') for d in valid_data])\n",
    "print(len(x_valid), y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "from gensim.models import KeyedVectors\n",
    "news_path = '../data/GoogleNews-vectors-negative300.bin'\n",
    "words = KeyedVectors.load_word2vec_format(news_path, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2sum(vector_data, dim):\n",
    "    mecab = MeCab.Tagger()\n",
    "    vector_sum = np.zeros((len(vector_data), dim))\n",
    "    for i, v in enumerate(vector_data):\n",
    "        morph = mecab.parse(v)\n",
    "        words_ = morph.split('\\n')\n",
    "        vector = np.zeros(dim)\n",
    "        cnt = 0\n",
    "        for word in words_:\n",
    "            noun = word.split('\\t')[0]\n",
    "            if noun == 'EOS':\n",
    "                if cnt == 0:\n",
    "                    break\n",
    "                vector_sum[i] = (vector / cnt)\n",
    "                break\n",
    "            \n",
    "            try :\n",
    "                cnt += 1\n",
    "                vector += words[noun]\n",
    "            except KeyError as error:\n",
    "                continue\n",
    "    return vector_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8708\n",
      "(8708, 300)\n"
     ]
    }
   ],
   "source": [
    "x_feature = vec2sum(x_train, 300)\n",
    "print(len(x_train))\n",
    "print(x_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "dim = words['US'].shape[0] # 単語ベクトルの次元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 4])\n",
      "torch.Size([1, 300])\n",
      "tensor([[0.0803, 0.3842, 0.3113, 0.2243]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# 71\n",
    "w = np.random.rand(dim, 4)\n",
    "w = torch.randn(dim, 4, requires_grad = True)\n",
    "print(w.shape)\n",
    "\n",
    "# 1次元=>2次元\n",
    "x_f = np.array([x_feature[0]]) \n",
    "x_f = torch.tensor(x_f, requires_grad = True)\n",
    "print(x_f.shape)\n",
    "\n",
    "x_f_w = func.softmax(torch.mm(x_f.float(), w.float()))\n",
    "print(x_f_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0803, 0.3842, 0.3113, 0.2243],\n",
      "        [0.2538, 0.4910, 0.0384, 0.2169],\n",
      "        [0.3479, 0.3272, 0.2324, 0.0925],\n",
      "        [0.1113, 0.3930, 0.2663, 0.2294]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 複数事例\n",
    "x_f_Y = torch.tensor(x_feature[0:4], requires_grad = True)\n",
    "Y_ = func.softmax(torch.mm(x_f_Y.float(), w.float()).float(), dim = 1)\n",
    "print(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([[0.0803, 0.3842, 0.3113, 0.2243]], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3313, grad_fn=<NllLossBackward>)\n",
      "tensor([[-0.0003, -0.0020,  0.0034, -0.0010],\n",
      "        [ 0.0022,  0.0133, -0.0222,  0.0068],\n",
      "        [-0.0002, -0.0015,  0.0026, -0.0008],\n",
      "        ...,\n",
      "        [-0.0017, -0.0103,  0.0172, -0.0052],\n",
      "        [-0.0006, -0.0038,  0.0064, -0.0020],\n",
      "        [-0.0003, -0.0018,  0.0029, -0.0009]])\n",
      "tensor(1.3313, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from math import exp, log\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(y_train[0])\n",
    "y = criterion(x_f_w, torch.tensor(np.array([y_train[0]])).long())\n",
    "print(x_f_w)\n",
    "y.backward()\n",
    "print(y)\n",
    "print(w.grad)\n",
    "\n",
    "# 検算\n",
    "x_sum = 0\n",
    "for i in x_f_w[0]:\n",
    "    x_sum += exp(i)\n",
    "x_ = x_f_w[0][y_train[0]]\n",
    "ans = -x_ + log(x_sum)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3869, grad_fn=<NllLossBackward>)\n",
      "tensor([[-0.0033,  0.0036,  0.0012, -0.0014],\n",
      "        [-0.0015,  0.0213, -0.0309,  0.0111],\n",
      "        [ 0.0020, -0.0038,  0.0036, -0.0018],\n",
      "        ...,\n",
      "        [-0.0033, -0.0096,  0.0210, -0.0081],\n",
      "        [-0.0004, -0.0036,  0.0072, -0.0032],\n",
      "        [ 0.0021, -0.0040,  0.0062, -0.0043]])\n"
     ]
    }
   ],
   "source": [
    "# 複数事例\n",
    "Y = criterion(Y_, torch.tensor(y_train[0:4]).long())\n",
    "print(Y)\n",
    "Y.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = func.softmax(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet(dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "num_epochs = 100\n",
    "save_path = '../data/params.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, num_batches, x_train, y_train, optimizer, model):\n",
    "    \n",
    "    # epoch毎の損失と精度を保持するリスト\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    num_data = x_train.shape[0]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # epoch毎の損失と精度\n",
    "        running_loss = 0.0\n",
    "        accuracy = 0.0\n",
    "        \n",
    "        # 開始時間のメモ\n",
    "        t = time.time()\n",
    "        \n",
    "        # ミニバッチ学習のために訓練データのインデックスをランダムに並べ替える\n",
    "        index = np.random.permutation(num_data)\n",
    "        \n",
    "        for i in range(0, num_data, num_batches):\n",
    "            # NNへの入力と正解ラベル\n",
    "            in_, label = torch.tensor(x_train[index[i : i + num_batches if i + num_batches < num_data else num_data]]), \\\n",
    "                         torch.tensor(y_train[index[i : i + num_batches if i + num_batches < num_data else num_data]]).long()\n",
    "        \n",
    "            # 最適化関数の初期化\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # 予測とロスの計算\n",
    "            out_ = model(in_.float())\n",
    "            loss = criterion(out_, label)\n",
    "            \n",
    "            _, idx = torch.max(out_, 1)\n",
    "            \n",
    "            # バッチ数のラベルが出てくるので，いくつ正解しているかカウント\n",
    "            cnt = 0\n",
    "            for i in range(idx.shape[0]):\n",
    "                if idx[i] == label[i]:\n",
    "                    cnt += 1\n",
    "            accuracy += cnt / idx.shape[0]\n",
    "        \n",
    "            # パラメーターの更新\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data\n",
    "        \n",
    "        # 各種データの出力・保存\n",
    "        num_loop = num_data / num_batches\n",
    "        print('[ epoch:{0}, time:{3} ]  acc: {1:.4f}  loss:{2:.4f}'.format(epoch + 1, accuracy / num_loop, running_loss / num_loop, time.time() - t))\n",
    "        accs.append(accuracy / num_loop)\n",
    "        losses.append(running_loss / num_loop)\n",
    "        \n",
    "        # 状況の保存\n",
    "        torch.save({\n",
    "          'epoch': epoch,\n",
    "          'model_state_dict': model.state_dict(),\n",
    "          'optimizer_state_dict': optimizer.state_dict(),\n",
    "          'loss': running_loss / num_loop,\n",
    "          }, save_path)\n",
    "        \n",
    "    return (model, accs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x, y, model):\n",
    "    total = x.shape[0]\n",
    "    cnt = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        in_, label = torch.from_numpy(np.array([x[i]])), \\\n",
    "                     torch.tensor(np.array([y[i]])).long()\n",
    "        p = model(in_.float())\n",
    "        _, index = torch.max(p, 1)\n",
    "        if index == label:\n",
    "            cnt += 1\n",
    "    return (cnt * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:2.4124608039855957 ]  acc: 0.8096  loss:0.9744\n",
      "[ epoch:2, time:2.3835861682891846 ]  acc: 0.8228  loss:0.9322\n",
      "[ epoch:3, time:2.3446249961853027 ]  acc: 0.8246  loss:0.9265\n",
      "[ epoch:4, time:2.354555130004883 ]  acc: 0.8259  loss:0.9237\n",
      "[ epoch:5, time:2.348209857940674 ]  acc: 0.8275  loss:0.9218\n",
      "[ epoch:6, time:2.3424880504608154 ]  acc: 0.8276  loss:0.9204\n",
      "[ epoch:7, time:2.334503173828125 ]  acc: 0.8283  loss:0.9193\n",
      "[ epoch:8, time:2.3277649879455566 ]  acc: 0.8290  loss:0.9184\n",
      "[ epoch:9, time:2.335322141647339 ]  acc: 0.8289  loss:0.9177\n",
      "[ epoch:10, time:2.335034132003784 ]  acc: 0.8297  loss:0.9172\n",
      "[ epoch:11, time:2.4011900424957275 ]  acc: 0.8294  loss:0.9166\n",
      "[ epoch:12, time:2.375515937805176 ]  acc: 0.8294  loss:0.9162\n",
      "[ epoch:13, time:2.3343920707702637 ]  acc: 0.8303  loss:0.9157\n",
      "[ epoch:14, time:2.3292810916900635 ]  acc: 0.8307  loss:0.9153\n",
      "[ epoch:15, time:2.3154046535491943 ]  acc: 0.8310  loss:0.9150\n",
      "[ epoch:16, time:2.358058214187622 ]  acc: 0.8308  loss:0.9147\n",
      "[ epoch:17, time:2.3211898803710938 ]  acc: 0.8313  loss:0.9143\n",
      "[ epoch:18, time:2.330265998840332 ]  acc: 0.8316  loss:0.9141\n",
      "[ epoch:19, time:2.3606269359588623 ]  acc: 0.8316  loss:0.9139\n",
      "[ epoch:20, time:2.482545852661133 ]  acc: 0.8315  loss:0.9136\n",
      "[ epoch:21, time:2.3282508850097656 ]  acc: 0.8325  loss:0.9134\n",
      "[ epoch:22, time:2.32476806640625 ]  acc: 0.8323  loss:0.9132\n",
      "[ epoch:23, time:2.336207866668701 ]  acc: 0.8325  loss:0.9130\n",
      "[ epoch:24, time:2.324209690093994 ]  acc: 0.8325  loss:0.9127\n",
      "[ epoch:25, time:2.329379081726074 ]  acc: 0.8330  loss:0.9127\n",
      "[ epoch:26, time:2.3352789878845215 ]  acc: 0.8322  loss:0.9124\n",
      "[ epoch:27, time:2.3407318592071533 ]  acc: 0.8330  loss:0.9123\n",
      "[ epoch:28, time:2.3342840671539307 ]  acc: 0.8325  loss:0.9121\n",
      "[ epoch:29, time:2.329598903656006 ]  acc: 0.8328  loss:0.9120\n",
      "[ epoch:30, time:2.3250420093536377 ]  acc: 0.8328  loss:0.9117\n",
      "[ epoch:31, time:2.328754186630249 ]  acc: 0.8329  loss:0.9116\n",
      "[ epoch:32, time:2.335188865661621 ]  acc: 0.8331  loss:0.9113\n",
      "[ epoch:33, time:2.319293975830078 ]  acc: 0.8330  loss:0.9105\n",
      "[ epoch:34, time:2.3276119232177734 ]  acc: 0.8396  loss:0.9038\n",
      "[ epoch:35, time:2.313363790512085 ]  acc: 0.8576  loss:0.8923\n",
      "[ epoch:36, time:2.3223438262939453 ]  acc: 0.8814  loss:0.8787\n",
      "[ epoch:37, time:2.334479331970215 ]  acc: 0.8989  loss:0.8661\n",
      "[ epoch:38, time:2.3266959190368652 ]  acc: 0.9050  loss:0.8581\n",
      "[ epoch:39, time:2.3081958293914795 ]  acc: 0.9081  loss:0.8525\n",
      "[ epoch:40, time:2.311107873916626 ]  acc: 0.9104  loss:0.8483\n",
      "[ epoch:41, time:2.3190369606018066 ]  acc: 0.9150  loss:0.8450\n",
      "[ epoch:42, time:2.310749053955078 ]  acc: 0.9165  loss:0.8424\n",
      "[ epoch:43, time:2.3089568614959717 ]  acc: 0.9181  loss:0.8400\n",
      "[ epoch:44, time:2.378668785095215 ]  acc: 0.9201  loss:0.8384\n",
      "[ epoch:45, time:2.455411911010742 ]  acc: 0.9204  loss:0.8366\n",
      "[ epoch:46, time:2.3882617950439453 ]  acc: 0.9226  loss:0.8355\n",
      "[ epoch:47, time:2.3209750652313232 ]  acc: 0.9224  loss:0.8340\n",
      "[ epoch:48, time:2.339406967163086 ]  acc: 0.9240  loss:0.8332\n",
      "[ epoch:49, time:2.325566053390503 ]  acc: 0.9236  loss:0.8322\n",
      "[ epoch:50, time:2.311375856399536 ]  acc: 0.9234  loss:0.8312\n",
      "[ epoch:51, time:2.3014369010925293 ]  acc: 0.9247  loss:0.8303\n",
      "[ epoch:52, time:2.3052263259887695 ]  acc: 0.9256  loss:0.8295\n",
      "[ epoch:53, time:2.30546498298645 ]  acc: 0.9265  loss:0.8287\n",
      "[ epoch:54, time:2.3146860599517822 ]  acc: 0.9268  loss:0.8280\n",
      "[ epoch:55, time:2.3138020038604736 ]  acc: 0.9279  loss:0.8274\n",
      "[ epoch:56, time:2.3071250915527344 ]  acc: 0.9279  loss:0.8268\n",
      "[ epoch:57, time:2.3105762004852295 ]  acc: 0.9298  loss:0.8261\n",
      "[ epoch:58, time:2.3227641582489014 ]  acc: 0.9295  loss:0.8256\n",
      "[ epoch:59, time:2.3006479740142822 ]  acc: 0.9290  loss:0.8251\n",
      "[ epoch:60, time:2.309345006942749 ]  acc: 0.9298  loss:0.8247\n",
      "[ epoch:61, time:2.3015480041503906 ]  acc: 0.9310  loss:0.8242\n",
      "[ epoch:62, time:2.29129695892334 ]  acc: 0.9303  loss:0.8238\n",
      "[ epoch:63, time:2.320884943008423 ]  acc: 0.9316  loss:0.8234\n",
      "[ epoch:64, time:2.305176258087158 ]  acc: 0.9314  loss:0.8229\n",
      "[ epoch:65, time:2.311148166656494 ]  acc: 0.9322  loss:0.8224\n",
      "[ epoch:66, time:2.3109781742095947 ]  acc: 0.9325  loss:0.8222\n",
      "[ epoch:67, time:2.310389995574951 ]  acc: 0.9333  loss:0.8217\n",
      "[ epoch:68, time:2.316159963607788 ]  acc: 0.9320  loss:0.8214\n",
      "[ epoch:69, time:2.3159799575805664 ]  acc: 0.9332  loss:0.8209\n",
      "[ epoch:70, time:2.3280441761016846 ]  acc: 0.9335  loss:0.8206\n",
      "[ epoch:71, time:2.314356803894043 ]  acc: 0.9345  loss:0.8203\n",
      "[ epoch:72, time:2.3163650035858154 ]  acc: 0.9339  loss:0.8200\n",
      "[ epoch:73, time:2.310915231704712 ]  acc: 0.9351  loss:0.8196\n",
      "[ epoch:74, time:2.309945821762085 ]  acc: 0.9347  loss:0.8194\n",
      "[ epoch:75, time:2.3037610054016113 ]  acc: 0.9359  loss:0.8191\n",
      "[ epoch:76, time:2.499281167984009 ]  acc: 0.9352  loss:0.8188\n",
      "[ epoch:77, time:2.3871278762817383 ]  acc: 0.9360  loss:0.8184\n",
      "[ epoch:78, time:2.65867280960083 ]  acc: 0.9364  loss:0.8182\n",
      "[ epoch:79, time:2.3523662090301514 ]  acc: 0.9358  loss:0.8179\n",
      "[ epoch:80, time:2.320591688156128 ]  acc: 0.9363  loss:0.8176\n",
      "[ epoch:81, time:2.3526558876037598 ]  acc: 0.9373  loss:0.8174\n",
      "[ epoch:82, time:2.3143222332000732 ]  acc: 0.9363  loss:0.8173\n",
      "[ epoch:83, time:2.3198108673095703 ]  acc: 0.9362  loss:0.8169\n",
      "[ epoch:84, time:2.3181440830230713 ]  acc: 0.9375  loss:0.8167\n",
      "[ epoch:85, time:2.354206085205078 ]  acc: 0.9373  loss:0.8165\n",
      "[ epoch:86, time:2.3230957984924316 ]  acc: 0.9375  loss:0.8163\n",
      "[ epoch:87, time:2.308216094970703 ]  acc: 0.9375  loss:0.8160\n",
      "[ epoch:88, time:2.31532621383667 ]  acc: 0.9376  loss:0.8158\n",
      "[ epoch:89, time:2.3276422023773193 ]  acc: 0.9382  loss:0.8155\n",
      "[ epoch:90, time:2.3138539791107178 ]  acc: 0.9381  loss:0.8152\n",
      "[ epoch:91, time:2.3109540939331055 ]  acc: 0.9389  loss:0.8152\n",
      "[ epoch:92, time:2.313598871231079 ]  acc: 0.9382  loss:0.8149\n",
      "[ epoch:93, time:2.3118598461151123 ]  acc: 0.9390  loss:0.8147\n",
      "[ epoch:94, time:2.3180291652679443 ]  acc: 0.9381  loss:0.8145\n",
      "[ epoch:95, time:2.3186070919036865 ]  acc: 0.9390  loss:0.8143\n",
      "[ epoch:96, time:2.319727897644043 ]  acc: 0.9391  loss:0.8142\n",
      "[ epoch:97, time:2.3365302085876465 ]  acc: 0.9403  loss:0.8138\n",
      "[ epoch:98, time:2.3159549236297607 ]  acc: 0.9391  loss:0.8137\n",
      "[ epoch:99, time:2.307727098464966 ]  acc: 0.9401  loss:0.8136\n",
      "[ epoch:100, time:2.3383748531341553 ]  acc: 0.9398  loss:0.8134\n"
     ]
    }
   ],
   "source": [
    "model, accs, losses = train(num_epochs, 1, x_feature, y_train, optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.72156505914468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print(eval(vec2sum(x_test, dim), y_test, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.00551217271475\n"
     ]
    }
   ],
   "source": [
    "print(eval(x_feature, y_train, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.73897058823529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print(eval(vec2sum(x_valid, dim), y_valid, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(accs))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(x, accs, color = 'red', linewidth = 2, label = 'accuracy')\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(x, losses, color = 'green', linewidth = 2, label = 'loss')\n",
    "ax.legend()\n",
    "ax2.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:1.2299458980560303 ]  acc: 0.9403  loss:0.8131\n",
      "[ epoch:2, time:1.2168068885803223 ]  acc: 0.9398  loss:0.8130\n",
      "[ epoch:3, time:1.2212750911712646 ]  acc: 0.9403  loss:0.8129\n",
      "[ epoch:4, time:1.2183418273925781 ]  acc: 0.9401  loss:0.8128\n",
      "[ epoch:5, time:1.2208530902862549 ]  acc: 0.9405  loss:0.8128\n",
      "[ epoch:6, time:1.2097220420837402 ]  acc: 0.9406  loss:0.8127\n",
      "[ epoch:7, time:1.2130041122436523 ]  acc: 0.9403  loss:0.8126\n",
      "[ epoch:8, time:1.2185940742492676 ]  acc: 0.9413  loss:0.8125\n",
      "[ epoch:9, time:1.2233190536499023 ]  acc: 0.9410  loss:0.8125\n",
      "[ epoch:10, time:1.2464919090270996 ]  acc: 0.9406  loss:0.8124\n",
      "[ epoch:11, time:1.2311592102050781 ]  acc: 0.9412  loss:0.8123\n",
      "[ epoch:12, time:1.2162859439849854 ]  acc: 0.9414  loss:0.8122\n",
      "[ epoch:13, time:1.230281114578247 ]  acc: 0.9417  loss:0.8121\n",
      "[ epoch:14, time:1.2297370433807373 ]  acc: 0.9417  loss:0.8120\n",
      "[ epoch:15, time:1.2217228412628174 ]  acc: 0.9420  loss:0.8120\n",
      "[ epoch:16, time:1.229909896850586 ]  acc: 0.9412  loss:0.8119\n",
      "[ epoch:17, time:1.2277719974517822 ]  acc: 0.9427  loss:0.8118\n",
      "[ epoch:18, time:1.2299270629882812 ]  acc: 0.9410  loss:0.8117\n",
      "[ epoch:19, time:1.2184720039367676 ]  acc: 0.9424  loss:0.8117\n",
      "[ epoch:20, time:1.2373731136322021 ]  acc: 0.9420  loss:0.8116\n",
      "[ epoch:21, time:1.216177225112915 ]  acc: 0.9424  loss:0.8115\n",
      "[ epoch:22, time:1.2130680084228516 ]  acc: 0.9427  loss:0.8114\n",
      "[ epoch:23, time:1.2212920188903809 ]  acc: 0.9424  loss:0.8114\n",
      "[ epoch:24, time:1.2191581726074219 ]  acc: 0.9422  loss:0.8113\n",
      "[ epoch:25, time:1.2153589725494385 ]  acc: 0.9424  loss:0.8112\n",
      "[ epoch:26, time:1.2343599796295166 ]  acc: 0.9426  loss:0.8112\n",
      "[ epoch:27, time:1.221086025238037 ]  acc: 0.9433  loss:0.8111\n",
      "[ epoch:28, time:1.2286860942840576 ]  acc: 0.9430  loss:0.8110\n",
      "[ epoch:29, time:1.2174651622772217 ]  acc: 0.9428  loss:0.8110\n",
      "[ epoch:30, time:1.2226719856262207 ]  acc: 0.9433  loss:0.8109\n",
      "[ epoch:31, time:1.2147729396820068 ]  acc: 0.9427  loss:0.8108\n",
      "[ epoch:32, time:1.215979814529419 ]  acc: 0.9433  loss:0.8107\n",
      "[ epoch:33, time:1.2244558334350586 ]  acc: 0.9426  loss:0.8107\n",
      "[ epoch:34, time:1.2301411628723145 ]  acc: 0.9426  loss:0.8106\n",
      "[ epoch:35, time:1.2502899169921875 ]  acc: 0.9430  loss:0.8106\n",
      "[ epoch:36, time:1.2459862232208252 ]  acc: 0.9428  loss:0.8105\n",
      "[ epoch:37, time:1.2188498973846436 ]  acc: 0.9434  loss:0.8105\n",
      "[ epoch:38, time:1.231799840927124 ]  acc: 0.9428  loss:0.8104\n",
      "[ epoch:39, time:1.2233607769012451 ]  acc: 0.9436  loss:0.8103\n",
      "[ epoch:40, time:1.2245399951934814 ]  acc: 0.9427  loss:0.8102\n",
      "[ epoch:41, time:1.2153890132904053 ]  acc: 0.9438  loss:0.8102\n",
      "[ epoch:42, time:1.2098817825317383 ]  acc: 0.9434  loss:0.8102\n",
      "[ epoch:43, time:1.2386293411254883 ]  acc: 0.9429  loss:0.8101\n",
      "[ epoch:44, time:1.2149839401245117 ]  acc: 0.9435  loss:0.8100\n",
      "[ epoch:45, time:1.2613348960876465 ]  acc: 0.9440  loss:0.8099\n",
      "[ epoch:46, time:1.2625269889831543 ]  acc: 0.9433  loss:0.8099\n",
      "[ epoch:47, time:1.2298610210418701 ]  acc: 0.9435  loss:0.8098\n",
      "[ epoch:48, time:1.2115702629089355 ]  acc: 0.9440  loss:0.8098\n",
      "[ epoch:49, time:1.2239022254943848 ]  acc: 0.9438  loss:0.8097\n",
      "[ epoch:50, time:1.2555580139160156 ]  acc: 0.9437  loss:0.8096\n",
      "[ epoch:51, time:1.3231537342071533 ]  acc: 0.9436  loss:0.8096\n",
      "[ epoch:52, time:1.3266167640686035 ]  acc: 0.9435  loss:0.8095\n",
      "[ epoch:53, time:1.2960660457611084 ]  acc: 0.9436  loss:0.8095\n",
      "[ epoch:54, time:1.2931368350982666 ]  acc: 0.9437  loss:0.8094\n",
      "[ epoch:55, time:1.726478099822998 ]  acc: 0.9440  loss:0.8093\n",
      "[ epoch:56, time:1.6441659927368164 ]  acc: 0.9444  loss:0.8093\n",
      "[ epoch:57, time:1.5699598789215088 ]  acc: 0.9441  loss:0.8093\n",
      "[ epoch:58, time:1.3271398544311523 ]  acc: 0.9443  loss:0.8092\n",
      "[ epoch:59, time:1.2809889316558838 ]  acc: 0.9443  loss:0.8091\n",
      "[ epoch:60, time:1.3284502029418945 ]  acc: 0.9445  loss:0.8091\n",
      "[ epoch:61, time:1.3724658489227295 ]  acc: 0.9443  loss:0.8090\n",
      "[ epoch:62, time:1.3257920742034912 ]  acc: 0.9449  loss:0.8089\n",
      "[ epoch:63, time:1.3328211307525635 ]  acc: 0.9445  loss:0.8089\n",
      "[ epoch:64, time:1.249758005142212 ]  acc: 0.9450  loss:0.8089\n",
      "[ epoch:65, time:1.3087868690490723 ]  acc: 0.9443  loss:0.8088\n",
      "[ epoch:66, time:1.769752025604248 ]  acc: 0.9441  loss:0.8088\n",
      "[ epoch:67, time:1.580387830734253 ]  acc: 0.9444  loss:0.8087\n",
      "[ epoch:68, time:1.2931551933288574 ]  acc: 0.9448  loss:0.8086\n",
      "[ epoch:69, time:1.2760508060455322 ]  acc: 0.9445  loss:0.8086\n",
      "[ epoch:70, time:1.3392181396484375 ]  acc: 0.9451  loss:0.8086\n",
      "[ epoch:71, time:1.3738629817962646 ]  acc: 0.9456  loss:0.8084\n",
      "[ epoch:72, time:1.3176660537719727 ]  acc: 0.9453  loss:0.8085\n",
      "[ epoch:73, time:1.293572187423706 ]  acc: 0.9449  loss:0.8084\n",
      "[ epoch:74, time:1.2988049983978271 ]  acc: 0.9449  loss:0.8084\n",
      "[ epoch:75, time:1.2932908535003662 ]  acc: 0.9455  loss:0.8083\n",
      "[ epoch:76, time:1.3522529602050781 ]  acc: 0.9445  loss:0.8082\n",
      "[ epoch:77, time:1.2758848667144775 ]  acc: 0.9452  loss:0.8082\n",
      "[ epoch:78, time:1.2647979259490967 ]  acc: 0.9455  loss:0.8081\n",
      "[ epoch:79, time:1.4718217849731445 ]  acc: 0.9452  loss:0.8081\n",
      "[ epoch:80, time:1.6231229305267334 ]  acc: 0.9456  loss:0.8080\n",
      "[ epoch:81, time:1.3532459735870361 ]  acc: 0.9450  loss:0.8080\n",
      "[ epoch:82, time:1.4030320644378662 ]  acc: 0.9450  loss:0.8079\n",
      "[ epoch:83, time:1.297299861907959 ]  acc: 0.9451  loss:0.8078\n",
      "[ epoch:84, time:1.329392910003662 ]  acc: 0.9458  loss:0.8078\n",
      "[ epoch:85, time:1.3236310482025146 ]  acc: 0.9459  loss:0.8078\n",
      "[ epoch:86, time:1.3259389400482178 ]  acc: 0.9460  loss:0.8077\n",
      "[ epoch:87, time:1.333629846572876 ]  acc: 0.9458  loss:0.8077\n",
      "[ epoch:88, time:1.2792890071868896 ]  acc: 0.9461  loss:0.8077\n",
      "[ epoch:89, time:1.2651646137237549 ]  acc: 0.9459  loss:0.8076\n",
      "[ epoch:90, time:1.3254940509796143 ]  acc: 0.9452  loss:0.8076\n",
      "[ epoch:91, time:1.3091208934783936 ]  acc: 0.9457  loss:0.8075\n",
      "[ epoch:92, time:1.3298048973083496 ]  acc: 0.9459  loss:0.8075\n",
      "[ epoch:93, time:1.3319499492645264 ]  acc: 0.9457  loss:0.8074\n",
      "[ epoch:94, time:1.2578282356262207 ]  acc: 0.9465  loss:0.8074\n",
      "[ epoch:95, time:1.322295904159546 ]  acc: 0.9461  loss:0.8073\n",
      "[ epoch:96, time:1.3940749168395996 ]  acc: 0.9464  loss:0.8073\n",
      "[ epoch:97, time:1.3315460681915283 ]  acc: 0.9464  loss:0.8073\n",
      "[ epoch:98, time:1.3323860168457031 ]  acc: 0.9465  loss:0.8072\n",
      "[ epoch:99, time:1.3647172451019287 ]  acc: 0.9468  loss:0.8072\n",
      "[ epoch:100, time:1.3490030765533447 ]  acc: 0.9465  loss:0.8071\n"
     ]
    }
   ],
   "source": [
    "model, accs, losses = train(num_epochs, 2, x_feature, y_train, optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:0.7223527431488037 ]  acc: 0.9467  loss:0.8070\n",
      "[ epoch:2, time:0.7348952293395996 ]  acc: 0.9468  loss:0.8070\n",
      "[ epoch:3, time:0.7094190120697021 ]  acc: 0.9467  loss:0.8070\n",
      "[ epoch:4, time:0.7223870754241943 ]  acc: 0.9468  loss:0.8069\n",
      "[ epoch:5, time:0.7000508308410645 ]  acc: 0.9471  loss:0.8069\n",
      "[ epoch:6, time:0.7212178707122803 ]  acc: 0.9471  loss:0.8069\n",
      "[ epoch:7, time:0.6981651782989502 ]  acc: 0.9471  loss:0.8069\n",
      "[ epoch:8, time:0.6987061500549316 ]  acc: 0.9471  loss:0.8068\n",
      "[ epoch:9, time:0.7117719650268555 ]  acc: 0.9467  loss:0.8068\n",
      "[ epoch:10, time:0.6960241794586182 ]  acc: 0.9469  loss:0.8068\n",
      "[ epoch:11, time:0.6966609954833984 ]  acc: 0.9467  loss:0.8068\n",
      "[ epoch:12, time:0.664086103439331 ]  acc: 0.9472  loss:0.8067\n",
      "[ epoch:13, time:0.6468842029571533 ]  acc: 0.9468  loss:0.8067\n",
      "[ epoch:14, time:0.69569993019104 ]  acc: 0.9476  loss:0.8067\n",
      "[ epoch:15, time:0.6935529708862305 ]  acc: 0.9472  loss:0.8067\n",
      "[ epoch:16, time:0.6890969276428223 ]  acc: 0.9473  loss:0.8067\n",
      "[ epoch:17, time:0.6854820251464844 ]  acc: 0.9474  loss:0.8067\n",
      "[ epoch:18, time:0.6922948360443115 ]  acc: 0.9472  loss:0.8066\n",
      "[ epoch:19, time:0.695976972579956 ]  acc: 0.9471  loss:0.8066\n",
      "[ epoch:20, time:0.6969177722930908 ]  acc: 0.9471  loss:0.8066\n",
      "[ epoch:21, time:0.7005400657653809 ]  acc: 0.9471  loss:0.8066\n",
      "[ epoch:22, time:0.6949348449707031 ]  acc: 0.9472  loss:0.8066\n",
      "[ epoch:23, time:0.6904008388519287 ]  acc: 0.9472  loss:0.8065\n",
      "[ epoch:24, time:0.697080135345459 ]  acc: 0.9471  loss:0.8065\n",
      "[ epoch:25, time:0.6927478313446045 ]  acc: 0.9473  loss:0.8065\n",
      "[ epoch:26, time:0.6647989749908447 ]  acc: 0.9472  loss:0.8065\n",
      "[ epoch:27, time:0.6714639663696289 ]  acc: 0.9473  loss:0.8065\n",
      "[ epoch:28, time:0.6449868679046631 ]  acc: 0.9475  loss:0.8064\n",
      "[ epoch:29, time:0.6545608043670654 ]  acc: 0.9474  loss:0.8064\n",
      "[ epoch:30, time:0.706439733505249 ]  acc: 0.9473  loss:0.8064\n",
      "[ epoch:31, time:0.6841049194335938 ]  acc: 0.9475  loss:0.8064\n",
      "[ epoch:32, time:0.7010390758514404 ]  acc: 0.9471  loss:0.8064\n",
      "[ epoch:33, time:0.6912398338317871 ]  acc: 0.9473  loss:0.8063\n",
      "[ epoch:34, time:0.6951019763946533 ]  acc: 0.9472  loss:0.8063\n",
      "[ epoch:35, time:0.6574578285217285 ]  acc: 0.9472  loss:0.8063\n",
      "[ epoch:36, time:0.6442489624023438 ]  acc: 0.9476  loss:0.8063\n",
      "[ epoch:37, time:0.6468939781188965 ]  acc: 0.9472  loss:0.8062\n",
      "[ epoch:38, time:0.6452517509460449 ]  acc: 0.9476  loss:0.8062\n",
      "[ epoch:39, time:0.6478991508483887 ]  acc: 0.9473  loss:0.8062\n",
      "[ epoch:40, time:0.6500780582427979 ]  acc: 0.9476  loss:0.8062\n",
      "[ epoch:41, time:0.648582935333252 ]  acc: 0.9476  loss:0.8062\n",
      "[ epoch:42, time:0.657742977142334 ]  acc: 0.9473  loss:0.8061\n",
      "[ epoch:43, time:0.6525156497955322 ]  acc: 0.9475  loss:0.8061\n",
      "[ epoch:44, time:0.6611850261688232 ]  acc: 0.9475  loss:0.8061\n",
      "[ epoch:45, time:0.6533689498901367 ]  acc: 0.9473  loss:0.8061\n",
      "[ epoch:46, time:0.6554141044616699 ]  acc: 0.9474  loss:0.8061\n",
      "[ epoch:47, time:0.6530330181121826 ]  acc: 0.9474  loss:0.8061\n",
      "[ epoch:48, time:0.6523430347442627 ]  acc: 0.9476  loss:0.8060\n",
      "[ epoch:49, time:0.6500389575958252 ]  acc: 0.9473  loss:0.8060\n",
      "[ epoch:50, time:0.6512987613677979 ]  acc: 0.9475  loss:0.8060\n",
      "[ epoch:51, time:0.6693830490112305 ]  acc: 0.9477  loss:0.8060\n",
      "[ epoch:52, time:0.6586530208587646 ]  acc: 0.9476  loss:0.8060\n",
      "[ epoch:53, time:0.6543099880218506 ]  acc: 0.9472  loss:0.8059\n",
      "[ epoch:54, time:0.6539871692657471 ]  acc: 0.9475  loss:0.8059\n",
      "[ epoch:55, time:0.64886474609375 ]  acc: 0.9475  loss:0.8059\n",
      "[ epoch:56, time:0.6487088203430176 ]  acc: 0.9473  loss:0.8059\n",
      "[ epoch:57, time:0.6547341346740723 ]  acc: 0.9475  loss:0.8058\n",
      "[ epoch:58, time:0.6430621147155762 ]  acc: 0.9475  loss:0.8059\n",
      "[ epoch:59, time:0.6810030937194824 ]  acc: 0.9480  loss:0.8058\n",
      "[ epoch:60, time:0.6808798313140869 ]  acc: 0.9475  loss:0.8058\n",
      "[ epoch:61, time:0.7020950317382812 ]  acc: 0.9474  loss:0.8058\n",
      "[ epoch:62, time:0.7055537700653076 ]  acc: 0.9477  loss:0.8058\n",
      "[ epoch:63, time:0.6820931434631348 ]  acc: 0.9475  loss:0.8057\n",
      "[ epoch:64, time:0.657599925994873 ]  acc: 0.9474  loss:0.8057\n",
      "[ epoch:65, time:0.6494300365447998 ]  acc: 0.9476  loss:0.8057\n",
      "[ epoch:66, time:0.6519269943237305 ]  acc: 0.9477  loss:0.8057\n",
      "[ epoch:67, time:0.6480090618133545 ]  acc: 0.9477  loss:0.8057\n",
      "[ epoch:68, time:0.6533219814300537 ]  acc: 0.9476  loss:0.8057\n",
      "[ epoch:69, time:0.6502118110656738 ]  acc: 0.9479  loss:0.8056\n",
      "[ epoch:70, time:0.6529531478881836 ]  acc: 0.9476  loss:0.8056\n",
      "[ epoch:71, time:0.6477839946746826 ]  acc: 0.9477  loss:0.8056\n",
      "[ epoch:72, time:0.6470441818237305 ]  acc: 0.9477  loss:0.8056\n",
      "[ epoch:73, time:0.6484229564666748 ]  acc: 0.9479  loss:0.8055\n",
      "[ epoch:74, time:0.6470780372619629 ]  acc: 0.9476  loss:0.8056\n",
      "[ epoch:75, time:0.6466028690338135 ]  acc: 0.9477  loss:0.8055\n",
      "[ epoch:76, time:0.6563830375671387 ]  acc: 0.9477  loss:0.8055\n",
      "[ epoch:77, time:0.6465306282043457 ]  acc: 0.9477  loss:0.8055\n",
      "[ epoch:78, time:0.6473829746246338 ]  acc: 0.9480  loss:0.8055\n",
      "[ epoch:79, time:0.6382462978363037 ]  acc: 0.9476  loss:0.8054\n",
      "[ epoch:80, time:0.6472568511962891 ]  acc: 0.9477  loss:0.8054\n",
      "[ epoch:81, time:0.638779878616333 ]  acc: 0.9475  loss:0.8054\n",
      "[ epoch:82, time:0.6443760395050049 ]  acc: 0.9479  loss:0.8054\n",
      "[ epoch:83, time:0.6555910110473633 ]  acc: 0.9480  loss:0.8054\n",
      "[ epoch:84, time:0.6491708755493164 ]  acc: 0.9476  loss:0.8054\n",
      "[ epoch:85, time:0.6518778800964355 ]  acc: 0.9477  loss:0.8053\n",
      "[ epoch:86, time:0.6514639854431152 ]  acc: 0.9480  loss:0.8053\n",
      "[ epoch:87, time:0.6435420513153076 ]  acc: 0.9480  loss:0.8053\n",
      "[ epoch:88, time:0.6535232067108154 ]  acc: 0.9481  loss:0.8053\n",
      "[ epoch:89, time:0.6473510265350342 ]  acc: 0.9481  loss:0.8053\n",
      "[ epoch:90, time:0.646665096282959 ]  acc: 0.9481  loss:0.8053\n",
      "[ epoch:91, time:0.6509389877319336 ]  acc: 0.9481  loss:0.8052\n",
      "[ epoch:92, time:0.6459259986877441 ]  acc: 0.9474  loss:0.8052\n",
      "[ epoch:93, time:0.6471641063690186 ]  acc: 0.9483  loss:0.8052\n",
      "[ epoch:94, time:0.6510210037231445 ]  acc: 0.9482  loss:0.8052\n",
      "[ epoch:95, time:0.6533119678497314 ]  acc: 0.9484  loss:0.8052\n",
      "[ epoch:96, time:0.6496648788452148 ]  acc: 0.9482  loss:0.8051\n",
      "[ epoch:97, time:0.6432693004608154 ]  acc: 0.9479  loss:0.8051\n",
      "[ epoch:98, time:0.6454219818115234 ]  acc: 0.9481  loss:0.8051\n",
      "[ epoch:99, time:0.642510175704956 ]  acc: 0.9479  loss:0.8051\n",
      "[ epoch:100, time:0.646359920501709 ]  acc: 0.9479  loss:0.8051\n"
     ]
    }
   ],
   "source": [
    "model, accs, losses = train(num_epochs, 4, x_feature, y_train, optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet2(nn.Module):\n",
    "    def __init__(self, input_size, h_size, output_size):\n",
    "        super(MyNet2, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, h_size)\n",
    "        self.fc2 = torch.nn.Linear(h_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = func.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = func.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet2(dim, 100, 4)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "num_epochs = 100\n",
    "save_path = '../data/params.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ epoch:1, time:1.9604780673980713 ]  acc: 0.7980  loss:0.9566\n",
      "[ epoch:2, time:1.9771151542663574 ]  acc: 0.8275  loss:0.9162\n",
      "[ epoch:3, time:1.977762222290039 ]  acc: 0.8302  loss:0.9133\n",
      "[ epoch:4, time:1.9852077960968018 ]  acc: 0.8315  loss:0.9117\n",
      "[ epoch:5, time:1.9634521007537842 ]  acc: 0.8329  loss:0.9102\n",
      "[ epoch:6, time:1.950193166732788 ]  acc: 0.8334  loss:0.9081\n",
      "[ epoch:7, time:1.9881999492645264 ]  acc: 0.8423  loss:0.8988\n",
      "[ epoch:8, time:1.9931762218475342 ]  acc: 0.8706  loss:0.8739\n",
      "[ epoch:9, time:1.972059726715088 ]  acc: 0.8817  loss:0.8624\n",
      "[ epoch:10, time:2.067525863647461 ]  acc: 0.9057  loss:0.8441\n",
      "[ epoch:11, time:1.9598169326782227 ]  acc: 0.9229  loss:0.8267\n",
      "[ epoch:12, time:1.9589958190917969 ]  acc: 0.9262  loss:0.8206\n",
      "[ epoch:13, time:1.940685749053955 ]  acc: 0.9274  loss:0.8177\n",
      "[ epoch:14, time:1.9604358673095703 ]  acc: 0.9328  loss:0.8139\n",
      "[ epoch:15, time:1.970794916152954 ]  acc: 0.9356  loss:0.8119\n",
      "[ epoch:16, time:1.9566781520843506 ]  acc: 0.9370  loss:0.8097\n",
      "[ epoch:17, time:1.9802191257476807 ]  acc: 0.9388  loss:0.8079\n",
      "[ epoch:18, time:1.975951910018921 ]  acc: 0.9409  loss:0.8057\n",
      "[ epoch:19, time:1.9887659549713135 ]  acc: 0.9404  loss:0.8054\n",
      "[ epoch:20, time:1.9831209182739258 ]  acc: 0.9428  loss:0.8038\n",
      "[ epoch:21, time:1.9556999206542969 ]  acc: 0.9429  loss:0.8031\n",
      "[ epoch:22, time:1.9643220901489258 ]  acc: 0.9443  loss:0.8023\n",
      "[ epoch:23, time:1.9957759380340576 ]  acc: 0.9437  loss:0.8022\n",
      "[ epoch:24, time:1.9321320056915283 ]  acc: 0.9457  loss:0.8004\n",
      "[ epoch:25, time:1.9713997840881348 ]  acc: 0.9468  loss:0.7997\n",
      "[ epoch:26, time:2.0037660598754883 ]  acc: 0.9471  loss:0.7988\n",
      "[ epoch:27, time:2.0370140075683594 ]  acc: 0.9469  loss:0.7992\n",
      "[ epoch:28, time:2.0430891513824463 ]  acc: 0.9469  loss:0.7982\n",
      "[ epoch:29, time:2.0206680297851562 ]  acc: 0.9486  loss:0.7971\n",
      "[ epoch:30, time:2.0545809268951416 ]  acc: 0.9474  loss:0.7974\n",
      "[ epoch:31, time:2.0346860885620117 ]  acc: 0.9505  loss:0.7954\n",
      "[ epoch:32, time:2.067831039428711 ]  acc: 0.9511  loss:0.7951\n",
      "[ epoch:33, time:2.0045859813690186 ]  acc: 0.9513  loss:0.7949\n",
      "[ epoch:34, time:2.007248878479004 ]  acc: 0.9527  loss:0.7936\n",
      "[ epoch:35, time:2.0440080165863037 ]  acc: 0.9518  loss:0.7937\n",
      "[ epoch:36, time:1.97432279586792 ]  acc: 0.9536  loss:0.7928\n",
      "[ epoch:37, time:1.997805118560791 ]  acc: 0.9529  loss:0.7927\n",
      "[ epoch:38, time:1.9778199195861816 ]  acc: 0.9535  loss:0.7923\n",
      "[ epoch:39, time:2.0337371826171875 ]  acc: 0.9542  loss:0.7916\n",
      "[ epoch:40, time:2.015695810317993 ]  acc: 0.9556  loss:0.7906\n",
      "[ epoch:41, time:1.9960839748382568 ]  acc: 0.9564  loss:0.7901\n",
      "[ epoch:42, time:2.0470752716064453 ]  acc: 0.9556  loss:0.7900\n",
      "[ epoch:43, time:2.0613927841186523 ]  acc: 0.9565  loss:0.7893\n",
      "[ epoch:44, time:2.0025651454925537 ]  acc: 0.9568  loss:0.7897\n",
      "[ epoch:45, time:2.160844087600708 ]  acc: 0.9574  loss:0.7888\n",
      "[ epoch:46, time:1.9525470733642578 ]  acc: 0.9567  loss:0.7889\n",
      "[ epoch:47, time:2.0448782444000244 ]  acc: 0.9573  loss:0.7885\n",
      "[ epoch:48, time:1.967756986618042 ]  acc: 0.9576  loss:0.7879\n",
      "[ epoch:49, time:2.0139920711517334 ]  acc: 0.9588  loss:0.7872\n",
      "[ epoch:50, time:2.095806837081909 ]  acc: 0.9581  loss:0.7878\n",
      "[ epoch:51, time:1.9860572814941406 ]  acc: 0.9593  loss:0.7866\n",
      "[ epoch:52, time:1.9864652156829834 ]  acc: 0.9593  loss:0.7861\n",
      "[ epoch:53, time:1.9945778846740723 ]  acc: 0.9604  loss:0.7856\n",
      "[ epoch:54, time:1.9730761051177979 ]  acc: 0.9613  loss:0.7849\n",
      "[ epoch:55, time:2.000502109527588 ]  acc: 0.9605  loss:0.7852\n",
      "[ epoch:56, time:1.9457688331604004 ]  acc: 0.9615  loss:0.7844\n",
      "[ epoch:57, time:1.9555208683013916 ]  acc: 0.9613  loss:0.7844\n",
      "[ epoch:58, time:2.0227339267730713 ]  acc: 0.9610  loss:0.7846\n",
      "[ epoch:59, time:1.9652280807495117 ]  acc: 0.9622  loss:0.7837\n",
      "[ epoch:60, time:1.9655170440673828 ]  acc: 0.9615  loss:0.7841\n",
      "[ epoch:61, time:1.9730198383331299 ]  acc: 0.9622  loss:0.7833\n",
      "[ epoch:62, time:1.9857630729675293 ]  acc: 0.9628  loss:0.7831\n",
      "[ epoch:63, time:1.9799132347106934 ]  acc: 0.9626  loss:0.7833\n",
      "[ epoch:64, time:1.970167875289917 ]  acc: 0.9626  loss:0.7826\n",
      "[ epoch:65, time:1.9523890018463135 ]  acc: 0.9622  loss:0.7830\n",
      "[ epoch:66, time:2.022843837738037 ]  acc: 0.9628  loss:0.7825\n",
      "[ epoch:67, time:1.9570951461791992 ]  acc: 0.9627  loss:0.7825\n",
      "[ epoch:68, time:2.01216197013855 ]  acc: 0.9628  loss:0.7823\n",
      "[ epoch:69, time:1.9804468154907227 ]  acc: 0.9626  loss:0.7821\n",
      "[ epoch:70, time:1.9701004028320312 ]  acc: 0.9634  loss:0.7818\n",
      "[ epoch:71, time:1.9670121669769287 ]  acc: 0.9633  loss:0.7815\n",
      "[ epoch:72, time:1.9900977611541748 ]  acc: 0.9633  loss:0.7817\n",
      "[ epoch:73, time:2.039212942123413 ]  acc: 0.9636  loss:0.7814\n",
      "[ epoch:74, time:2.015615940093994 ]  acc: 0.9636  loss:0.7813\n",
      "[ epoch:75, time:2.0323591232299805 ]  acc: 0.9637  loss:0.7811\n",
      "[ epoch:76, time:2.0143039226531982 ]  acc: 0.9635  loss:0.7813\n",
      "[ epoch:77, time:1.9686520099639893 ]  acc: 0.9636  loss:0.7810\n",
      "[ epoch:78, time:1.957068920135498 ]  acc: 0.9634  loss:0.7812\n",
      "[ epoch:79, time:2.000148057937622 ]  acc: 0.9637  loss:0.7808\n",
      "[ epoch:80, time:2.0012199878692627 ]  acc: 0.9637  loss:0.7810\n",
      "[ epoch:81, time:2.0539729595184326 ]  acc: 0.9637  loss:0.7809\n",
      "[ epoch:82, time:1.9803850650787354 ]  acc: 0.9635  loss:0.7808\n",
      "[ epoch:83, time:2.0610899925231934 ]  acc: 0.9636  loss:0.7809\n",
      "[ epoch:84, time:2.041614055633545 ]  acc: 0.9639  loss:0.7805\n",
      "[ epoch:85, time:2.0158040523529053 ]  acc: 0.9638  loss:0.7806\n",
      "[ epoch:86, time:2.0438857078552246 ]  acc: 0.9638  loss:0.7808\n",
      "[ epoch:87, time:2.0223119258880615 ]  acc: 0.9639  loss:0.7804\n",
      "[ epoch:88, time:2.0613110065460205 ]  acc: 0.9639  loss:0.7804\n",
      "[ epoch:89, time:1.9792120456695557 ]  acc: 0.9639  loss:0.7803\n",
      "[ epoch:90, time:1.9768130779266357 ]  acc: 0.9638  loss:0.7804\n",
      "[ epoch:91, time:1.9595682621002197 ]  acc: 0.9641  loss:0.7802\n",
      "[ epoch:92, time:1.9911839962005615 ]  acc: 0.9641  loss:0.7802\n",
      "[ epoch:93, time:1.9840712547302246 ]  acc: 0.9641  loss:0.7801\n",
      "[ epoch:94, time:1.970968246459961 ]  acc: 0.9641  loss:0.7802\n",
      "[ epoch:95, time:1.9921720027923584 ]  acc: 0.9641  loss:0.7802\n",
      "[ epoch:96, time:1.9960808753967285 ]  acc: 0.9641  loss:0.7802\n",
      "[ epoch:97, time:2.0746679306030273 ]  acc: 0.9639  loss:0.7801\n",
      "[ epoch:98, time:1.9917309284210205 ]  acc: 0.9641  loss:0.7801\n",
      "[ epoch:99, time:2.0418519973754883 ]  acc: 0.9639  loss:0.7802\n",
      "[ epoch:100, time:2.0482211112976074 ]  acc: 0.9638  loss:0.7803\n"
     ]
    }
   ],
   "source": [
    "model, accs2, losses2 = train(num_epochs, 2, x_feature, y_train, optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.37132352941177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taimu/yes/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "print(eval(vec2sum(x_valid, dim), y_valid, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(accs2))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(x, accs2, color = 'red', linewidth = 2, label = 'accuracy')\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(x, losses2, color = 'green', linewidth = 2, label = 'loss')\n",
    "ax.legend()\n",
    "ax2.legend()\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
